# Transformer models trained on Reddit "STUDIO"-dataset
In this project, I tried out several machine learning and deep learning approaches in order to find the best solution for NER task that was based on a new label, that is, “STUDIO”. Posts and comments of “movies” Subreddit were used as Dataset. The imbalanced data distribution was presented, and a training, dev and test datasets were built. Two machine learning models including Random Forest and Support Vector Machine were used based on numerical features from tf-idf vectorizer. Three transformer-based models including BERT, DistilBERT and RoBERTa were also trained and tested on the textual data. Comparisons between models and hyperparameters were done, and 92,4% F1 score for the machine learning model, 94,4% F1 score for the transformer-based model and 92,5% F1 score for the spaCy’s toc2vec model were achieved on the testing set. Transformer-based models were summarized and experimented. Cased, large RoBERTa model and large BERT cased were found giving better performances than the uncased, base ones. DistilBERT has a faster computation speed with a bit lower metrics, while RoBERTa gives higher evaluation metrics with more computational resources required.
